{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba55f1f6-56f9-4830-94a4-d3fe2a7455ee",
   "metadata": {},
   "source": [
    "# Hybrid recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bdf4716-b517-4aa3-bd08-f6dad50b756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librairies\n",
    "# classic Librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#loading embeddings\n",
    "import pickle\n",
    "\n",
    "#sklearn utils\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#surprise\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import train_test_split #really different from sklearn's ? \n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fbf63f04-98a3-42f3-a33c-33d217f00319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for cleaner display\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5610ecec-a0df-43ff-8968-6c5e9ab2ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load article metadata\n",
    "data_articles = pd.read_csv(\"data/archive/articles_metadata.csv\")\n",
    "# Ensure ordering matches the embeddings file\n",
    "data_articles = data_articles.sort_values(\"article_id\").reset_index(drop=True)\n",
    "\n",
    "# Load embeddings (shape ≈ [n_articles, 250])\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d26baa5e-eed6-496e-8097-72d536d1404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de data_articles : (364047, 5)\n",
      "['article_id', 'category_id', 'created_at_ts', 'publisher_id', 'words_count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250\n",
       "3           3            1  1408468313000             0          230\n",
       "4           4            1  1407071171000             0          162"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape de data_articles :\", data_articles.shape)\n",
    "print(data_articles.columns.tolist())\n",
    "data_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1dbc4e02-88fd-4b93-8c81-998e15063c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 2.2. Renommage et transformation de colonnes\\ndata_articles = data_articles.rename(columns={\\n    \"category_id\": \"category\",\\n    \"publisher_id\": \"publisher\",\\n    \"created_at_ts\": \"created_at\"\\n})\\n\\n# Convertir created_at en datetime\\ndata_articles[\"created_at\"] = pd.to_datetime(data_articles[\"created_at\"], unit=\"s\", origin=\"unix\")\\n\\n# Garder uniquement les colonnes utiles\\ndata_articles = data_articles[[\"article_id\", \"category\", \"publisher\", \"words_count\", \"created_at\"]]\\n\\nprint(\"Après renommage :\", data_articles.shape)\\ndata_articles.head()\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional renaming of columns\n",
    "\"\"\"# 2.2. Renommage et transformation de colonnes\n",
    "data_articles = data_articles.rename(columns={\n",
    "    \"category_id\": \"category\",\n",
    "    \"publisher_id\": \"publisher\",\n",
    "    \"created_at_ts\": \"created_at\"\n",
    "})\n",
    "\n",
    "# Convertir created_at en datetime\n",
    "data_articles[\"created_at\"] = pd.to_datetime(data_articles[\"created_at\"], unit=\"s\", origin=\"unix\")\n",
    "\n",
    "# Garder uniquement les colonnes utiles\n",
    "data_articles = data_articles[[\"article_id\", \"category\", \"publisher\", \"words_count\", \"created_at\"]]\n",
    "\n",
    "print(\"Après renommage :\", data_articles.shape)\n",
    "data_articles.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3359a4dc-844e-4249-84d1-95ae5f3fa9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type embeddings : <class 'numpy.ndarray'>\n",
      "Shape embeddings : (364047, 250)\n",
      "Articles dans data_articles : 364047, Lignes embeddings : 364047\n"
     ]
    }
   ],
   "source": [
    "# Embedding checker\n",
    "# 3.1. Charger le pickle embeddings (numpy ndarray)\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f_in:\n",
    "    embeddings = pickle.load(f_in)\n",
    "\n",
    "# 3.2. Vérifier la forme\n",
    "print(\"Type embeddings :\", type(embeddings))\n",
    "print(\"Shape embeddings :\", embeddings.shape)\n",
    "# embeddings doit être de shape (n_articles, 250)\n",
    "\n",
    "# 3.3. Vérifier la correspondance entre embeddings et data_articles\n",
    "#      On suppose que les embeddings sont **dans le même ordre** que les lignes de data_articles.\n",
    "n_data_articles = data_articles.shape[0]\n",
    "n_emb  = embeddings.shape[0]\n",
    "print(f\"Articles dans data_articles : {n_data_articles}, Lignes embeddings : {n_emb}\")\n",
    "\n",
    "if n_data_articles != n_emb:\n",
    "    raise ValueError(\"Le nombre de lignes dans data_articles et dans embeddings ne correspond pas !\"\n",
    "                     \" VÉRIFIE L’ORDRE DES ARTICLES.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97a2ab05-d2fd-4f6e-add1-6097fc3c0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index CB prêt (NearestNeighbors).\n"
     ]
    }
   ],
   "source": [
    "# 4.1. Instancier NearestNeighbors\n",
    "CF_RADIUS = n_data_articles  # nombre de voisins à rescanner pour le blending\n",
    "nn_index = NearestNeighbors(n_neighbors=CF_RADIUS, metric=\"cosine\", algorithm=\"auto\")\n",
    "\n",
    "# 4.2. Entraîner l’index sur l’ensemble des embeddings\n",
    "nn_index.fit(embeddings)\n",
    "\n",
    "print(\"Index CB prêt (NearestNeighbors).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1240cdef-7b9f-47c0-be1c-62a2e665753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type cf_algo : <class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\n"
     ]
    }
   ],
   "source": [
    "# 5.1. Charger l’instance Surprise picklée (algo_cf)\n",
    "CF_MODEL_PATH = os.path.join(\"models_in_progress\", \"cf_model.pkl\")\n",
    "\n",
    "with open(CF_MODEL_PATH, \"rb\") as f_in:\n",
    "    cf_algo = pickle.load(f_in)\n",
    "\n",
    "# 5.2. Vérifier que cf_algo dispose bien de .predict, .train… etc.\n",
    "print(\"Type cf_algo :\", type(cf_algo))\n",
    "# Exemple d’attribut attendu : cf_algo.__class__ doit être surprise.prediction_algorithms.matrix_factorization.SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efab2c-71c5-4cde-8966-13a00ce70d8b",
   "metadata": {},
   "source": [
    "I don't need to reload dataset for CF since I have the model that's trained on it pickled\n",
    "\n",
    "I can move on to reconstruct my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7175e9e4-e664-4031-91f7-e1bd20385902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_profile(user_clicks):\n",
    "    \"\"\"\n",
    "    user_clicks : liste d'article_id déjà vus (ex. [157541, 280367, 71301])\n",
    "    Retourne un vecteur moyen des embeddings correspondants.\n",
    "    Si aucun clic, renvoie un vecteur nul de même dimension.\n",
    "    \"\"\"\n",
    "    if len(user_clicks) == 0:\n",
    "        # Cold-start user : vecteur nul\n",
    "        return np.zeros(embeddings.shape[1])\n",
    "\n",
    "    # Trouver les indices dans data_articles pour chaque article_id\n",
    "    idxs = data_articles.index[data_articles[\"article_id\"].isin(user_clicks)].tolist()\n",
    "    if len(idxs) == 0:\n",
    "        # Aucun match (utilisateur a cliqué sur des articles hors data_articles)\n",
    "        return np.zeros(embeddings.shape[1])\n",
    "\n",
    "    user_embs = embeddings[idxs]\n",
    "    return user_embs.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3957ccff-3322-4a31-9edb-9bd90c914eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cf_for_candidates(user_id, candidate_ids):\n",
    "    \"\"\"\n",
    "    user_id : int\n",
    "    candidate_ids : liste d'int (article_id)\n",
    "    Retourne un numpy array de score CF brute : cf_algo.predict(user_id, iid).est\n",
    "    \"\"\"\n",
    "    cf_scores = []\n",
    "    for iid in candidate_ids:\n",
    "        # on met r_ui=None car on ne connaît pas la vraie note\n",
    "        pred = cf_algo.predict(uid=user_id, iid=iid, r_ui=None, verbose=False)\n",
    "        cf_scores.append(pred.est)\n",
    "    return np.array(cf_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44f79934-2987-46fc-bbad-182bf3b802d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minmax(array):\n",
    "    \"\"\"\n",
    "    Ramène array dans [0,1] par un simple min-max scaling.\n",
    "    Si array.min() == array.max(), on renvoie un vecteur constant à 0.5.\n",
    "    \"\"\"\n",
    "    mn = array.min()\n",
    "    mx = array.max()\n",
    "    if mx > mn:\n",
    "        return (array - mn) / (mx - mn)\n",
    "    else:\n",
    "        return np.full_like(array, 0.5, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30f697d2-2e89-494a-ac61-8b9685d0dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(user_id, user_clicks, k=10, alpha=0.5, total_candidates=CF_RADIUS):\n",
    "    \"\"\"\n",
    "    Renvoie un DataFrame pandas des k articles recommandés pour user_id,\n",
    "    en blendant le score CB (similarité cos) et le score CF (prediction SVD).\n",
    "    \n",
    "    user_id        : int\n",
    "    user_clicks    : liste d'article_id déjà cliqués\n",
    "    k              : nombre d’articles à retourner\n",
    "    alpha          : poids du CF (0 <= alpha <= 1). ex. 0.5 pour 50% CF / 50% CB\n",
    "    total_candidates : taille du pool initial de candidats CB\n",
    "    \n",
    "    Sortie : DataFrame contenant [\n",
    "        article_id, category, publisher, words_count, created_at,\n",
    "        score_cb, score_cf, score_hybrid\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # ----- 1. Calculer le profil CB de l'utilisateur -----\n",
    "    user_vec = build_user_profile(user_clicks)  # vecteur 250-d\n",
    "    \n",
    "    # ----- 2. Récupérer le pool initial via NN sur embeddings -----\n",
    "    distances, indices = nn_index.kneighbors([user_vec], n_neighbors=total_candidates)\n",
    "    cand_idxs = indices[0]                # indices dans data_articles/embeddings\n",
    "    sims_cb = 1.0 - distances[0]          # cosinus similarity = 1 - distance\n",
    "    \n",
    "    # IDs des articles candidats\n",
    "    candidate_ids = data_articles.iloc[cand_idxs][\"article_id\"].tolist()\n",
    "    \n",
    "    # ----- 3. Construire le DataFrame brut des candidats -----\n",
    "    df_cand = pd.DataFrame({\n",
    "        \"article_id\": candidate_ids,\n",
    "        \"score_cb\": sims_cb\n",
    "    })\n",
    "    \n",
    "    # ----- 4. Calculer le score CF brut (cf_algo.predict) -----\n",
    "    raw_cf = score_cf_for_candidates(user_id, candidate_ids)\n",
    "    df_cand[\"score_cf_raw\"] = raw_cf\n",
    "    \n",
    "    # ----- 5. Normaliser le score CF en [0,1] -----\n",
    "    df_cand[\"score_cf\"] = normalize_minmax(df_cand[\"score_cf_raw\"].values)\n",
    "    \n",
    "    # ----- 6. Calculer le score hybride -----\n",
    "    df_cand[\"score_hybrid\"] = alpha * df_cand[\"score_cf\"] + (1 - alpha) * df_cand[\"score_cb\"]\n",
    "    \n",
    "    # ----- 7. Trier par score_hybrid et prendre les top-k -----\n",
    "    topk = (\n",
    "        df_cand\n",
    "        .sort_values(\"score_hybrid\", ascending=False)\n",
    "        .head(k)\n",
    "        .merge(\n",
    "            data_articles,\n",
    "            on=\"article_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ----- 8. Sélection / ordre des colonnes à renvoyer -----\n",
    "    return topk[[\n",
    "        \"article_id\",\n",
    "        \"category_id\",\n",
    "        \"publisher_id\",\n",
    "        \"words_count\",\n",
    "        \"created_at_ts\",\n",
    "        \"score_cb\",\n",
    "        \"score_cf\",\n",
    "        \"score_hybrid\"\n",
    "    ]].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2c4bde6-cf89-45e8-80ad-98278478de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommandations hybrides pour user 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>score_cb</th>\n",
       "      <th>score_cf</th>\n",
       "      <th>score_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83841</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1507100284000</td>\n",
       "      <td>0.440159</td>\n",
       "      <td>0.912931</td>\n",
       "      <td>0.723822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>157702</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>263</td>\n",
       "      <td>1507109598000</td>\n",
       "      <td>0.257656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.703062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>156625</td>\n",
       "      <td>281</td>\n",
       "      <td>0</td>\n",
       "      <td>241</td>\n",
       "      <td>1507204625000</td>\n",
       "      <td>0.240647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.696259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96386</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "      <td>1507536073000</td>\n",
       "      <td>0.302086</td>\n",
       "      <td>0.944853</td>\n",
       "      <td>0.687746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119600</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1507887563000</td>\n",
       "      <td>0.480693</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.674827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  publisher_id  words_count  created_at_ts  score_cb  score_cf  score_hybrid\n",
       "0       83841          174             0          155  1507100284000  0.440159  0.912931      0.723822\n",
       "1      157702          281             0          263  1507109598000  0.257656  1.000000      0.703062\n",
       "2      156625          281             0          241  1507204625000  0.240647  1.000000      0.696259\n",
       "3       96386          209             0          199  1507536073000  0.302086  0.944853      0.687746\n",
       "4      119600          247             0          223  1507887563000  0.480693  0.804250      0.674827"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple : user_id=1234 a cliqué sur ces articles\n",
    "test_user_id    = 10\n",
    "test_user_clicks = [81937, 112847]  # historique des articles cliqués\n",
    "\n",
    "# On appelle la fonction hybride\n",
    "recs = recommend_hybrid(\n",
    "    user_id=test_user_id,\n",
    "    user_clicks=test_user_clicks,\n",
    "    k=5,\n",
    "    alpha=0.6,            # 60% CF / 40% CB\n",
    "    total_candidates=n_data_articles\n",
    ")\n",
    "\n",
    "print(\"Recommandations hybrides pour user\", test_user_id)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab18e47-a3ad-44bc-9f56-03dd2be4fd44",
   "metadata": {},
   "source": [
    "nb de click par user sur un article / pondère par activité user lors de sa session (nb total de click par session)\n",
    "\n",
    "par user's session  : \\\n",
    "nb total de click \\\n",
    "nb de click par article\n",
    "\n",
    "temps passé sur chaque article \\\n",
    "nb de click sur un même lien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edc0ed-1d5c-479b-a412-072b2303d5e8",
   "metadata": {},
   "source": [
    "pour azure function deploy \n",
    "\n",
    "préparer une liste de user_id \\\n",
    "préparer des historiques différents\n",
    "\n",
    "préparer sur papier les plans d'architecture imaginée/souhaitée/mise en place \\\n",
    "qu'est c eque je déploie en blob / qu'est ce que je déploie en aure Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d5cd7-62ae-4350-b896-28587a48e36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
