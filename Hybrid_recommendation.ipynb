{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba55f1f6-56f9-4830-94a4-d3fe2a7455ee",
   "metadata": {},
   "source": [
    "# Hybrid recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1bdf4716-b517-4aa3-bd08-f6dad50b756e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librairies\n",
    "# classic Librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#loading embeddings\n",
    "import pickle\n",
    "\n",
    "#sklearn utils\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#surprise\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import train_test_split #really different from sklearn's ? \n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fbf63f04-98a3-42f3-a33c-33d217f00319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options for cleaner display\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "pd.set_option(\"display.width\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5610ecec-a0df-43ff-8968-6c5e9ab2ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type : <class 'numpy.ndarray'>\n",
      "Array numpy avec shape : (364047, 250)\n"
     ]
    }
   ],
   "source": [
    "# Load article metadata\n",
    "data_articles = pd.read_csv(\"data/archive/articles_metadata.csv\")\n",
    "# Ensure ordering matches the embeddings file\n",
    "data_articles = data_articles.sort_values(\"article_id\").reset_index(drop=True)\n",
    "\n",
    "# Load embeddings (shape ≈ [n_articles, 250])\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f:\n",
    "    embeddings = pickle.load(f)\n",
    "# check type\n",
    "print(\"Type :\", type(embeddings))\n",
    "\n",
    "if isinstance(embeddings, dict):\n",
    "    print(\"Clés :\", list(embeddings.keys())[:10])\n",
    "    if \"ids\" in embeddings:\n",
    "        print(\"Premier id :\", embeddings[\"ids\"][0])\n",
    "    if \"vectors\" in embeddings:\n",
    "        print(\"Shape des vecteurs :\", embeddings[\"vectors\"].shape)\n",
    "\n",
    "elif isinstance(embeddings, (list, tuple)):\n",
    "    print(\"Longueur :\", len(embeddings))\n",
    "    print(\"Exemple élément[0] :\", type(embeddings[0]))\n",
    "    if hasattr(embeddings[0], \"shape\"):\n",
    "        print(\"Shape :\", embeddings[0].shape)\n",
    "\n",
    "elif hasattr(embeddings, \"shape\"):  # probablement un np.ndarray\n",
    "    print(\"Array numpy avec shape :\", embeddings.shape)\n",
    "\n",
    "else:\n",
    "    print(\"Contenu :\", str(embeddings)[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d26baa5e-eed6-496e-8097-72d536d1404c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de data_articles : (364047, 5)\n",
      "['article_id', 'category_id', 'created_at_ts', 'publisher_id', 'words_count']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1513144419000</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405341936000</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1408667706000</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1408468313000</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1407071171000</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  created_at_ts  publisher_id  words_count\n",
       "0           0            0  1513144419000             0          168\n",
       "1           1            1  1405341936000             0          189\n",
       "2           2            1  1408667706000             0          250\n",
       "3           3            1  1408468313000             0          230\n",
       "4           4            1  1407071171000             0          162"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape de data_articles :\", data_articles.shape)\n",
    "print(data_articles.columns.tolist())\n",
    "data_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "09c344ae-6c63-4cd4-b928-c1b606104fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364042</th>\n",
       "      <td>364042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364043</th>\n",
       "      <td>364043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364044</th>\n",
       "      <td>364044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364045</th>\n",
       "      <td>364045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364046</th>\n",
       "      <td>364046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>364047 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        article_id\n",
       "0                0\n",
       "1                1\n",
       "2                2\n",
       "3                3\n",
       "4                4\n",
       "...            ...\n",
       "364042      364042\n",
       "364043      364043\n",
       "364044      364044\n",
       "364045      364045\n",
       "364046      364046\n",
       "\n",
       "[364047 rows x 1 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_articles_shorter = data_articles[['article_id']]\n",
    "data_articles_shorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8c50ceeb-1c6f-48c0-bf38-71e2502ab653",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_article_shorter.to_csv(\"data/data_article_shorter\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1dbc4e02-88fd-4b93-8c81-998e15063c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 2.2. Renommage et transformation de colonnes\\ndata_articles = data_articles.rename(columns={\\n    \"category_id\": \"category\",\\n    \"publisher_id\": \"publisher\",\\n    \"created_at_ts\": \"created_at\"\\n})d\\n\\n# Convertir created_at en datetime\\ndata_articles[\"created_at\"] = pd.to_datetime(data_articles[\"created_at\"], unit=\"s\", origin=\"unix\")\\n\\n# Garder uniquement les colonnes utiles\\ndata_articles = data_articles[[\"article_id\", \"category\", \"publisher\", \"words_count\", \"created_at\"]]\\n\\nprint(\"Après renommage :\", data_articles.shape)\\ndata_articles.head()\\n'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optional renaming of columns\n",
    "\"\"\"# 2.2. Renommage et transformation de colonnes\n",
    "data_articles = data_articles.rename(columns={\n",
    "    \"category_id\": \"category\",\n",
    "    \"publisher_id\": \"publisher\",\n",
    "    \"created_at_ts\": \"created_at\"\n",
    "})d\n",
    "\n",
    "# Convertir created_at en datetime\n",
    "data_articles[\"created_at\"] = pd.to_datetime(data_articles[\"created_at\"], unit=\"s\", origin=\"unix\")\n",
    "\n",
    "# Garder uniquement les colonnes utiles\n",
    "data_articles = data_articles[[\"article_id\", \"category\", \"publisher\", \"words_count\", \"created_at\"]]\n",
    "\n",
    "print(\"Après renommage :\", data_articles.shape)\n",
    "data_articles.head()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6ee9820c-4688-4fd2-bd3d-f2dd4fc8eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09248701 0.07410172 0.06653015 0.04882732 0.04229694 0.03987891\n",
      " 0.03714959 0.03283883 0.03228257 0.02882201 0.02742614 0.02508928\n",
      " 0.02424399 0.02221346 0.02075701 0.02004806 0.01905697 0.01874528\n",
      " 0.01748906 0.01640469 0.01548621 0.0151256  0.01399427 0.013067\n",
      " 0.01237998]\n"
     ]
    }
   ],
   "source": [
    "# Embedding checker\n",
    "# 3.1. Charger le pickle embeddings (numpy ndarray)\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f_in:\n",
    "    embeddings = pickle.load(f_in)\n",
    "\n",
    "#il faut faire la réduction AVANT pour voir si l'embedding réduit est toujours compatible avec le data_articles\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "new_embed = pca.fit_transform(embeddings)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3359a4dc-844e-4249-84d1-95ae5f3fa9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type embeddings : <class 'numpy.ndarray'>\n",
      "Shape embeddings : (364047, 25)\n",
      "Articles dans data_articles : 364047, Lignes embeddings : 364047\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Embedding checker\n",
    "# 3.1. Charger le pickle embeddings (numpy ndarray)\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f_in:\n",
    "    embeddings = pickle.load(f_in)\"\"\"\n",
    "\n",
    "# 3.2. Vérifier la forme\n",
    "print(\"Type embeddings :\", type(new_embed))\n",
    "print(\"Shape embeddings :\", new_embed.shape)\n",
    "# embeddings doit être de shape (n_articles, 250)\n",
    "\n",
    "# 3.3. Vérifier la correspondance entre embeddings et data_articles\n",
    "#      On suppose que les embeddings sont **dans le même ordre** que les lignes de data_articles.\n",
    "n_data_articles = data_articles.shape[0]\n",
    "n_emb  = embeddings.shape[0]\n",
    "print(f\"Articles dans data_articles : {n_data_articles}, Lignes embeddings : {n_emb}\")\n",
    "\n",
    "if n_data_articles != n_emb:\n",
    "    raise ValueError(\"Le nombre de lignes dans data_articles et dans embeddings ne correspond pas !\"\n",
    "                     \" VÉRIFIE L’ORDRE DES ARTICLES.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0b9de30f-bb1f-4d0b-8a3c-8b8a84cbaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "97a2ab05-d2fd-4f6e-add1-6097fc3c0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index CB prêt (NearestNeighbors).\n",
      "trained in :  0.011813163757324219  secs\n"
     ]
    }
   ],
   "source": [
    "# 4.1. Instancier NearestNeighbors\n",
    "CF_RADIUS = n_data_articles  # nombre de voisins à rescanner pour le blending\n",
    "new_nn_index = NearestNeighbors(n_neighbors=CF_RADIUS, metric=\"cosine\", algorithm=\"auto\")\n",
    "\n",
    "# 4.2. Entraîner l’index sur l’ensemble des embeddings\n",
    "t0 = time.time()\n",
    "new_nn_index.fit(new_embed)#embeddings\n",
    "t1 = time.time()-t0\n",
    "print(\"Index CB prêt (NearestNeighbors).\")\n",
    "print(\"trained in : \", t1, \" secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a659db26-fb80-42a6-a8ba-a4a70b68d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'cosine',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 364047,\n",
       " 'p': 2,\n",
       " 'radius': 1.0}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nn_index.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1240cdef-7b9f-47c0-be1c-62a2e665753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type cf_algo : <class 'surprise.prediction_algorithms.matrix_factorization.SVD'>\n"
     ]
    }
   ],
   "source": [
    "# 5.1. Charger l’instance Surprise picklée (algo_cf)\n",
    "CF_MODEL_PATH = os.path.join(\"models_in_progress\", \"cf_model.pkl\")\n",
    "\n",
    "with open(CF_MODEL_PATH, \"rb\") as f_in:\n",
    "    cf_algo = pickle.load(f_in)\n",
    "\n",
    "# 5.2. Vérifier que cf_algo dispose bien de .predict, .train… etc.\n",
    "print(\"Type cf_algo :\", type(cf_algo))\n",
    "# Exemple d’attribut attendu : cf_algo.__class__ doit être surprise.prediction_algorithms.matrix_factorization.SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59efab2c-71c5-4cde-8966-13a00ce70d8b",
   "metadata": {},
   "source": [
    "I don't need to reload dataset for CF since I have the model that's trained on it pickled\n",
    "\n",
    "I can move on to reconstruct my functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "44f0d696-9ed9-46a3-9f1a-f8b39d9c9c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new embedding\n",
    "with open(\"new_embed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(new_embed, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5c55b3d8-5d4a-48ce-ba63-1ca2a9b8ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new index\n",
    "with open(\"new_nn_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(new_nn_index, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a1a21a8e-f353-450c-be2e-9587b169e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#check if files are pickled properly\\nimport binascii\\n\\nwith open(CF_MODEL_PATH, \"rb\") as f:\\n    head_model = f.read(8)\\n#print(CF_MODEL_PATH, binascii.hexlify(head_model).decode())\\n\\nwith open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f:\\n    head_embedd = f.read(8)\\n#print(binascii.hexlify(head_embedd).decode())\\n\\nNN_INDEX_PATH = os.getcwd()\\nPARENT = os.path.abspath(os.path.join(NN_INDEX_PATH, os.pardir))\\nPICKLE = os.path.join(PARENT, \"pickles\")\\nprint(PICKLE)\\n\\npath_to_nn = os.path.join(PICKLE, \"nn_index.pkl\")\\nwith open(path_to_nn, \"rb\") as f:\\n    head_index = f.read(8)\\n#print(binascii.hexlify(head_index).decode())\\n\\nprint(\"model:\", binascii.hexlify(head_model).decode(), \"\\n\\n\",\\n     \"embedding\", binascii.hexlify(head_embedd).decode(), \"\\n\\n\",\\n     \"index:\", binascii.hexlify(head_index).decode() )\\n     \\n'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#re-pickle files\n",
    "with open(\"articles_embeddings.pickle\", \"wb\") as f:\n",
    "    pickle.dump(embeddings, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"nn_index.pkl\", \"wb\") as f:\n",
    "    pickle.dump(nn_index, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open(\"cf_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cf_algo, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "#check if files are pickled properly\n",
    "import binascii\n",
    "\n",
    "with open(CF_MODEL_PATH, \"rb\") as f:\n",
    "    head_model = f.read(8)\n",
    "#print(CF_MODEL_PATH, binascii.hexlify(head_model).decode())\n",
    "\n",
    "with open(\"data/archive/articles_embeddings.pickle\", \"rb\") as f:\n",
    "    head_embedd = f.read(8)\n",
    "#print(binascii.hexlify(head_embedd).decode())\n",
    "\n",
    "NN_INDEX_PATH = os.getcwd()\n",
    "PARENT = os.path.abspath(os.path.join(NN_INDEX_PATH, os.pardir))\n",
    "PICKLE = os.path.join(PARENT, \"pickles\")\n",
    "print(PICKLE)\n",
    "\n",
    "path_to_nn = os.path.join(PICKLE, \"nn_index.pkl\")\n",
    "with open(path_to_nn, \"rb\") as f:\n",
    "    head_index = f.read(8)\n",
    "#print(binascii.hexlify(head_index).decode())\n",
    "\n",
    "print(\"model:\", binascii.hexlify(head_model).decode(), \"\\n\\n\",\n",
    "     \"embedding\", binascii.hexlify(head_embedd).decode(), \"\\n\\n\",\n",
    "     \"index:\", binascii.hexlify(head_index).decode() )\n",
    "     \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e0f4ae0a-0ae5-4902-8397-04b4d3e0df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_profile(user_clicks):\n",
    "    \"\"\"\n",
    "    user_clicks : liste d'article_id déjà vus (ex. [157541, 280367, 71301])\n",
    "    Retourne un vecteur moyen des embeddings correspondants.\n",
    "    Si aucun clic, renvoie un vecteur nul de même dimension.\n",
    "    \"\"\"\n",
    "    if len(user_clicks) == 0:\n",
    "        # Cold-start user : vecteur nul\n",
    "        #np.zeros(embeddings.shape[1])\n",
    "        return np.zeros(new_embed.shape[1])\n",
    "\n",
    "    # Trouver les indices dans data_articles pour chaque article_id\n",
    "    idxs = data_articles.index[data_articles[\"article_id\"].isin(user_clicks)].tolist()\n",
    "    #print(\"articles read : \", idxs)\n",
    "    if len(idxs) == 0:\n",
    "        # Aucun match (utilisateur a cliqué sur des articles hors data_articles)\n",
    "        #np.zeros(embeddings.shape[1])\n",
    "        return np.zeros(new_embed.shape[1])\n",
    "\n",
    "    user_embs = new_embed[idxs] # embeddings[idxs]\n",
    "    #print(\"user_emb : \", user_embs)\n",
    "    #print(\"final profile : \", user_embs.mean(axis=0))\n",
    "    return user_embs.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7175e9e4-e664-4031-91f7-e1bd20385902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_profile2(user_clicks):\n",
    "    \"\"\"\n",
    "    user_clicks : liste d'article_id déjà vus (ex. [157541, 280367, 71301])\n",
    "    Retourne un vecteur moyen des embeddings correspondants.\n",
    "    Si aucun clic, renvoie un vecteur nul de même dimension.\n",
    "    \"\"\"\n",
    "    if len(user_clicks) == 0:\n",
    "        # Cold-start user : vecteur nul\n",
    "        #np.zeros(embeddings.shape[1])\n",
    "        return np.zeros(new_embed.shape[1])\n",
    "\n",
    "    # Trouver les indices dans data_articles pour chaque article_id\n",
    "    idxs = data_articles_shorter.index[data_articles_shorter[\"article_id\"].isin(user_clicks)].tolist()\n",
    "    #print(\"articles read : \", idxs)\n",
    "    if len(idxs) == 0:\n",
    "        # Aucun match (utilisateur a cliqué sur des articles hors data_articles)\n",
    "        #np.zeros(embeddings.shape[1])\n",
    "        return np.zeros(new_embed.shape[1])\n",
    "\n",
    "    user_embs = new_embed[idxs] # embeddings[idxs]\n",
    "    #print(\"user_emb : \", user_embs)\n",
    "    #print(\"final profile : \", user_embs.mean(axis=0))\n",
    "    return user_embs.mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "44f79934-2987-46fc-bbad-182bf3b802d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minmax(array):\n",
    "    \"\"\"\n",
    "    Ramène array dans [0,1] par un simple min-max scaling.\n",
    "    Si array.min() == array.max(), on renvoie un vecteur constant à 0.5.\n",
    "    \"\"\"\n",
    "    mn = array.min()\n",
    "    mx = array.max()\n",
    "    if mx > mn:\n",
    "        return (array - mn) / (mx - mn)\n",
    "    else:\n",
    "        return np.full_like(array, 0.5, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3957ccff-3322-4a31-9edb-9bd90c914eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_cf_for_candidates(user_id, candidate_ids):\n",
    "    \"\"\"\n",
    "    user_id : int\n",
    "    candidate_ids : liste d'int (article_id)\n",
    "    Retourne un numpy array de score CF brute : cf_algo.predict(user_id, iid).est\n",
    "    \"\"\"\n",
    "    cf_scores = []\n",
    "    for iid in candidate_ids:\n",
    "        # on met r_ui=None car on ne connaît pas la vraie note\n",
    "        pred = cf_algo.predict(uid=user_id, iid=iid, r_ui=None, verbose=False)\n",
    "        cf_scores.append(pred.est)\n",
    "    return np.array(cf_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5252472e-50ad-47b9-ad2a-b18558606b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "NearestNeighbors(metric='cosine', n_neighbors=10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "with open(\"models_in_progress/nn_index.pkl\", 'rb') as file:\n",
    "        nn = pickle.load(file)\n",
    "        print(\"Data loaded successfully!\")\n",
    "        print(nn)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "30f697d2-2e89-494a-ac61-8b9685d0dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_hybrid(user_id, \n",
    "                     user_clicks, \n",
    "                     new_nn_index, \n",
    "                     k=10, \n",
    "                     alpha=0.5, \n",
    "                     total_candidates=CF_RADIUS):\n",
    "    \"\"\"\n",
    "    Renvoie un DataFrame pandas des k articles recommandés pour user_id,\n",
    "    en blendant le score CB (similarité cos) et le score CF (prediction SVD).\n",
    "    \n",
    "    user_id        : int\n",
    "    user_clicks    : liste d'article_id déjà cliqués\n",
    "    k              : nombre d’articles à retourner\n",
    "    alpha          : poids du CF (0 <= alpha <= 1). ex. 0.5 pour 50% CF / 50% CB\n",
    "    total_candidates : taille du pool initial de candidats CB\n",
    "    \n",
    "    Sortie : DataFrame contenant [\n",
    "        article_id, category, publisher, words_count, created_at,\n",
    "        score_cb, score_cf, score_hybrid\n",
    "    ]\n",
    "    \"\"\"\n",
    "    # ----- 1. Calculer le profil CB de l'utilisateur -----\n",
    "    user_vec = build_user_profile2(user_clicks)  # vecteur 250-d\n",
    "    \n",
    "    # ----- 2. Récupérer le pool initial via NN sur embeddings -----\n",
    "\n",
    "    distances, indices = new_nn_index.kneighbors([user_vec], n_neighbors=total_candidates)\n",
    "    cand_idxs = indices[0]                # indices dans data_articles/embeddings\n",
    "    sims_cb = 1.0 - distances[0]          # cosinus similarity = 1 - distance\n",
    "    \n",
    "    # IDs des articles candidats\n",
    "    candidate_ids = data_articles_shorter.iloc[cand_idxs][\"article_id\"].tolist() \n",
    "    #data_articles.iloc[cand_idxs][\"article_id\"].tolist()\n",
    "    \n",
    "    # ----- 3. Construire le DataFrame brut des candidats -----\n",
    "    df_cand = pd.DataFrame({\n",
    "        \"article_id\": candidate_ids,\n",
    "        \"score_cb\": sims_cb\n",
    "    })\n",
    "    \n",
    "    # ----- 4. Calculer le score CF brut (cf_algo.predict) -----\n",
    "    print('user_id type :', type(user_id))\n",
    "    print('candidate_ids type :',type(candidate_ids[2]))\n",
    "    raw_cf = score_cf_for_candidates(user_id, candidate_ids)\n",
    "    df_cand[\"score_cf_raw\"] = raw_cf\n",
    "    \n",
    "    # ----- 5. Normaliser le score CF en [0,1] -----\n",
    "    df_cand[\"score_cf\"] = normalize_minmax(df_cand[\"score_cf_raw\"].values)\n",
    "    \n",
    "    # ----- 6. Calculer le score hybride -----\n",
    "    df_cand[\"score_hybrid\"] = alpha * df_cand[\"score_cf\"] + (1 - alpha) * df_cand[\"score_cb\"]\n",
    "    \n",
    "    # ----- 7. Trier par score_hybrid et prendre les top-k -----\n",
    "    topk = (\n",
    "        df_cand\n",
    "        .sort_values(\"score_hybrid\", ascending=False)\n",
    "        .head(k)\n",
    "        .merge(\n",
    "            data_articles_shorter,\n",
    "            on=\"article_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # ----- 8. Sélection / ordre des colonnes à renvoyer -----\n",
    "    return topk[[\n",
    "        \"article_id\",\n",
    "        #\"category_id\",\n",
    "        #\"publisher_id\",\n",
    "        #\"words_count\",\n",
    "        #\"created_at_ts\",\n",
    "        #\"score_cb\",\n",
    "        #\"score_cf\",\n",
    "        \"score_hybrid\"\n",
    "    ]].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f2c4bde6-cf89-45e8-80ad-98278478de59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id type : <class 'int'>\n",
      "candidate_ids type : <class 'int'>\n",
      "Recommandations hybrides pour user 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>score_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1661</td>\n",
       "      <td>0.853442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975</td>\n",
       "      <td>0.849989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4866</td>\n",
       "      <td>0.820095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>984</td>\n",
       "      <td>0.812999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3449</td>\n",
       "      <td>0.810835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  score_hybrid\n",
       "0        1661      0.853442\n",
       "1        1975      0.849989\n",
       "2        4866      0.820095\n",
       "3         984      0.812999\n",
       "4        3449      0.810835"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exemple : user_id=1234 a cliqué sur ces articles\n",
    "test_user_id    = 10\n",
    "test_user_clicks = [101, 204, 305, 408, 509]  # historique des articles cliqués\n",
    "\n",
    "# On appelle la fonction hybride\n",
    "recs = recommend_hybrid(\n",
    "    user_id=test_user_id,\n",
    "    user_clicks=test_user_clicks,\n",
    "    new_nn_index = new_nn_index,\n",
    "    k=5,\n",
    "    alpha=0.6,            # 60% CF / 40% CB\n",
    "    total_candidates=n_data_articles\n",
    ")\n",
    "\n",
    "print(\"Recommandations hybrides pour user\", test_user_id)\n",
    "recs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab18e47-a3ad-44bc-9f56-03dd2be4fd44",
   "metadata": {},
   "source": [
    "nb de click par user sur un article / pondère par activité user lors de sa session (nb total de click par session)\n",
    "\n",
    "par user's session  : \\\n",
    "nb total de click \\\n",
    "nb de click par article\n",
    "\n",
    "temps passé sur chaque article \\\n",
    "nb de click sur un même lien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85edc0ed-1d5c-479b-a412-072b2303d5e8",
   "metadata": {},
   "source": [
    "pour azure function deploy \n",
    "\n",
    "préparer une liste de user_id \\\n",
    "préparer des historiques différents\n",
    "\n",
    "préparer sur papier les plans d'architecture imaginée/souhaitée/mise en place \\\n",
    "qu'est c eque je déploie en blob / qu'est ce que je déploie en aure Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8d5cd7-62ae-4350-b896-28587a48e36c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
