{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d05e78-10c8-4595-af23-8589b9064b4b",
   "metadata": {},
   "source": [
    "# Collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897f934a-8b9d-42bc-abbb-eb86e4f972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#librairies\n",
    "# classic Librairies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "#loading embeddings\n",
    "import pickle\n",
    "\n",
    "#sklearn utils\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#surprise\n",
    "from surprise import Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import train_test_split #really different from sklearn's ? \n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd44ebf-d55a-4eab-8a23-897f4e8ad7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385\n"
     ]
    }
   ],
   "source": [
    "#check if .ipynb files have been generated : len should be 385\n",
    "path = \"data/archive/clicks/clicks\"\n",
    "list_of_files = os.listdir(path)\n",
    "print(len(list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b47fa763-9a36-4470-8cae-ccc18c4dd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat all files in one\n",
    "dfs = []\n",
    "for file in list_of_files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    dfs.append(pd.read_csv(file_path))\n",
    "clicks_full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01789169-4135-4a89-992b-65e9e737a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Full size data set :\", clicks_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d24d237-267f-424d-94e6-554decda5325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        session_id  session_start  session_size  click_article_id  \\\n",
       "0        0  1506825423271737  1506825423000             2            157541   \n",
       "1        0  1506825423271737  1506825423000             2             68866   \n",
       "2        1  1506825426267738  1506825426000             2            235840   \n",
       "3        1  1506825426267738  1506825426000             2             96663   \n",
       "4        2  1506825435299739  1506825435000             2            119592   \n",
       "\n",
       "   click_timestamp  click_environment  click_deviceGroup  click_os  \\\n",
       "0    1506826828020                  4                  3        20   \n",
       "1    1506826858020                  4                  3        20   \n",
       "2    1506827017951                  4                  1        17   \n",
       "3    1506827047951                  4                  1        17   \n",
       "4    1506827090575                  4                  1        17   \n",
       "\n",
       "   click_country  click_region  click_referrer_type  \n",
       "0              1            20                    2  \n",
       "1              1            20                    2  \n",
       "2              1            16                    2  \n",
       "3              1            16                    2  \n",
       "4              1            24                    2  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading sample\n",
    "data_sample = pd.read_csv(\"data/archive/clicks_sample.csv\")\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a308d19-eee9-4a0f-833c-eab201d67217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#create rating\\nratings = (\\n    data_sample\\n    .groupby([\"user_id\",\"click_article_id\"])\\n    .size()\\n    .reset_index(name=\"rating\")\\n)\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#create rating\n",
    "ratings = (\n",
    "    data_sample\n",
    "    .groupby([\"user_id\",\"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6151a553-8e07-4fed-a20e-9df171a42ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e78ce9ed-81f2-4f07-9224-03cb34abcf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reader = Reader(rating_scale=(1, ratings.rating.max()))\\ndata   = Dataset.load_from_df(ratings[[\"user_id\",\"click_article_id\",\"rating\"]], reader)\\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''reader = Reader(rating_scale=(1, ratings.rating.max()))\n",
    "data   = Dataset.load_from_df(ratings[[\"user_id\",\"click_article_id\",\"rating\"]], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f500678b-50b2-4ed0-bd09-3233eda4dabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ratings[\"rating\"].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3eea621c-b23e-445e-8604-8df2beb7ae6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'algo = SVD(n_factors=50, random_state=42)\\nalgo.fit(trainset)\\npreds = algo.test(testset)\\nprint(\"RMSE:\", accuracy.rmse(preds))\\nprint(\"MAE: \", accuracy.mae(preds))'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''algo = SVD(n_factors=50, random_state=42)\n",
    "algo.fit(trainset)\n",
    "preds = algo.test(testset)\n",
    "print(\"RMSE:\", accuracy.rmse(preds))\n",
    "print(\"MAE: \", accuracy.mae(preds))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8017b037-6377-461a-afec-0bb8aca7409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1883, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>session_id</th>\n",
       "      <th>session_start</th>\n",
       "      <th>session_size</th>\n",
       "      <th>click_article_id</th>\n",
       "      <th>click_timestamp</th>\n",
       "      <th>click_environment</th>\n",
       "      <th>click_deviceGroup</th>\n",
       "      <th>click_os</th>\n",
       "      <th>click_country</th>\n",
       "      <th>click_region</th>\n",
       "      <th>click_referrer_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>157541</td>\n",
       "      <td>1506826828020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1506825423271737</td>\n",
       "      <td>1506825423000</td>\n",
       "      <td>2</td>\n",
       "      <td>68866</td>\n",
       "      <td>1506826858020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>235840</td>\n",
       "      <td>1506827017951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1506825426267738</td>\n",
       "      <td>1506825426000</td>\n",
       "      <td>2</td>\n",
       "      <td>96663</td>\n",
       "      <td>1506827047951</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1506825435299739</td>\n",
       "      <td>1506825435000</td>\n",
       "      <td>2</td>\n",
       "      <td>119592</td>\n",
       "      <td>1506827090575</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id        session_id  session_start  session_size  click_article_id  \\\n",
       "0        0  1506825423271737  1506825423000             2            157541   \n",
       "1        0  1506825423271737  1506825423000             2             68866   \n",
       "2        1  1506825426267738  1506825426000             2            235840   \n",
       "3        1  1506825426267738  1506825426000             2             96663   \n",
       "4        2  1506825435299739  1506825435000             2            119592   \n",
       "\n",
       "   click_timestamp  click_environment  click_deviceGroup  click_os  \\\n",
       "0    1506826828020                  4                  3        20   \n",
       "1    1506826858020                  4                  3        20   \n",
       "2    1506827017951                  4                  1        17   \n",
       "3    1506827047951                  4                  1        17   \n",
       "4    1506827090575                  4                  1        17   \n",
       "\n",
       "   click_country  click_region  click_referrer_type  \n",
       "0              1            20                    2  \n",
       "1              1            20                    2  \n",
       "2              1            16                    2  \n",
       "3              1            16                    2  \n",
       "4              1            24                    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1883 entries, 0 to 1882\n",
      "Data columns (total 12 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   user_id              1883 non-null   int64\n",
      " 1   session_id           1883 non-null   int64\n",
      " 2   session_start        1883 non-null   int64\n",
      " 3   session_size         1883 non-null   int64\n",
      " 4   click_article_id     1883 non-null   int64\n",
      " 5   click_timestamp      1883 non-null   int64\n",
      " 6   click_environment    1883 non-null   int64\n",
      " 7   click_deviceGroup    1883 non-null   int64\n",
      " 8   click_os             1883 non-null   int64\n",
      " 9   click_country        1883 non-null   int64\n",
      " 10  click_region         1883 non-null   int64\n",
      " 11  click_referrer_type  1883 non-null   int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 176.7 KB\n",
      "None\n",
      "Nulls : 0\n",
      "Doublons : 0\n",
      "Users uniques : 707\n",
      "Articles uniques : 323\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "# 2.2 Aperçu\n",
    "print(data_sample.shape)\n",
    "display(data_sample.head())\n",
    "print(data_sample.info())\n",
    "\n",
    "# 2.3 Valeurs manquantes / doublons\n",
    "print(\"Nulls :\", data_sample.isna().sum().sum())\n",
    "print(\"Doublons :\", data_sample.duplicated().sum())\n",
    "\n",
    "# 2.4 Nombre d’utilisateurs / articles\n",
    "print(\"Users uniques :\", data_sample[\"user_id\"].nunique())\n",
    "print(\"Articles uniques :\", data_sample[\"click_article_id\"].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4faf1d3-e799-4433-a24a-da4affc8c543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 3.2 Agréger en comptant les clics par (user, article)\\nratings = (\\n    data_sample\\n    .groupby([\"user_id\",\"click_article_id\"])\\n    .size()\\n    .reset_index(name=\"rating\")\\n)\\n\\nprint(ratings.shape)\\ndisplay(ratings.head())\\nprint(ratings[\"rating\"].describe())\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 3.2 Agréger en comptant les clics par (user, article)\n",
    "ratings = (\n",
    "    data_sample\n",
    "    .groupby([\"user_id\",\"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "\n",
    "print(ratings.shape)\n",
    "display(ratings.head())\n",
    "print(ratings[\"rating\"].describe())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9aba5a4-4675-45f6-8964-1329de159b9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from surprise import Dataset, Reader, SVD\\nfrom surprise.model_selection import train_test_split\\nfrom surprise import accuracy\\n\\n# 4.1 Création de l’objet Dataset\\nreader = Reader(rating_scale=(ratings[\"rating\"].min(), ratings[\"rating\"].max()))\\ndata = Dataset.load_from_df(ratings[[\"user_id\",\"click_article_id\",\"rating\"]], reader)\\n\\n# 4.2 Split train/test\\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\\n\\n# 4.3 Entraînement d’un SVD de base\\nalgo = SVD(n_factors=50, random_state=42)\\nalgo.fit(trainset)\\n\\n# 4.4 Évaluation\\npreds = algo.test(testset)\\nprint(\"RMSE :\", accuracy.rmse(preds))\\nprint(\"MAE  :\", accuracy.mae(preds))\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# 4.1 Création de l’objet Dataset\n",
    "reader = Reader(rating_scale=(ratings[\"rating\"].min(), ratings[\"rating\"].max()))\n",
    "data = Dataset.load_from_df(ratings[[\"user_id\",\"click_article_id\",\"rating\"]], reader)\n",
    "\n",
    "# 4.2 Split train/test\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4.3 Entraînement d’un SVD de base\n",
    "algo = SVD(n_factors=50, random_state=42)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 4.4 Évaluation\n",
    "preds = algo.test(testset)\n",
    "print(\"RMSE :\", accuracy.rmse(preds))\n",
    "print(\"MAE  :\", accuracy.mae(preds))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "575811b6-2aaf-43f0-9f8a-2a04ddd4278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from collections import defaultdict\\nimport numpy as np\\n\\ndef precision_recall_at_k(predictions, k=5, threshold=1.0):\\n    # Regrouper les prédictions par user\\n    user_pred = defaultdict(list)\\n    user_true = defaultdict(set)\\n    for uid, iid, true_r, est, _ in predictions:\\n        user_pred[uid].append((iid, est))\\n        if true_r >= threshold:\\n            user_true[uid].add(iid)\\n\\n    precisions, recalls = [], []\\n    for uid, preds in user_pred.items():\\n        # top-k par score estimé\\n        top_k = [iid for (iid, _) in sorted(preds, key=lambda x: x[1], reverse=True)[:k]]\\n        n_rel = len(user_true[uid])\\n        n_rec_k = len([i for i in top_k if i in user_true[uid]])\\n        precisions.append(n_rec_k / k)\\n        recalls.append(n_rec_k / n_rel if n_rel else 0)\\n\\n    return np.mean(precisions), np.mean(recalls)\\n\\nprec, rec = precision_recall_at_k(preds, k=5, threshold=1.0)\\nprint(f\"Precision@5 = {prec:.4f}, Recall@5 = {rec:.4f}\")\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "def precision_recall_at_k(predictions, k=5, threshold=1.0):\n",
    "    # Regrouper les prédictions par user\n",
    "    user_pred = defaultdict(list)\n",
    "    user_true = defaultdict(set)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        user_pred[uid].append((iid, est))\n",
    "        if true_r >= threshold:\n",
    "            user_true[uid].add(iid)\n",
    "\n",
    "    precisions, recalls = [], []\n",
    "    for uid, preds in user_pred.items():\n",
    "        # top-k par score estimé\n",
    "        top_k = [iid for (iid, _) in sorted(preds, key=lambda x: x[1], reverse=True)[:k]]\n",
    "        n_rel = len(user_true[uid])\n",
    "        n_rec_k = len([i for i in top_k if i in user_true[uid]])\n",
    "        precisions.append(n_rec_k / k)\n",
    "        recalls.append(n_rec_k / n_rel if n_rel else 0)\n",
    "\n",
    "    return np.mean(precisions), np.mean(recalls)\n",
    "\n",
    "prec, rec = precision_recall_at_k(preds, k=5, threshold=1.0)\n",
    "print(f\"Precision@5 = {prec:.4f}, Recall@5 = {rec:.4f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89af9577-4eb4-4c5c-8b24-4767c5e2bb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs uniques dans clicks : 46033\n",
      "IDs uniques dans meta   : 364047\n",
      "IDs en commun           : 46033 (100.0% des IDs de clics)\n",
      "IDs en clicks mais pas en meta : 0\n",
      "Quelques exemples : []\n",
      "IDs en meta mais pas en clicks : 318014\n",
      "Quelques exemples : [0, 1, 2, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "data_meta = pd.read_csv(\"data/archive/articles_metadata.csv\")\n",
    "# 1. Vérification de la correspondance des IDs\n",
    "click_ids = set(clicks_full[\"click_article_id\"].unique())\n",
    "meta_ids  = set(data_meta[\"article_id\"].unique())\n",
    "\n",
    "n_click_ids   = len(click_ids)\n",
    "n_meta_ids    = len(meta_ids)\n",
    "n_common_ids  = len(click_ids & meta_ids)\n",
    "\n",
    "print(f\"IDs uniques dans clicks : {n_click_ids}\")\n",
    "print(f\"IDs uniques dans meta   : {n_meta_ids}\")\n",
    "print(f\"IDs en commun           : {n_common_ids} ({n_common_ids/n_click_ids:.1%} des IDs de clics)\")\n",
    "\n",
    "# 2. IDs présents dans clicks mais pas dans meta\n",
    "missing_in_meta = click_ids - meta_ids\n",
    "print(f\"IDs en clicks mais pas en meta : {len(missing_in_meta)}\")\n",
    "print(\"Quelques exemples :\", list(missing_in_meta)[:10])\n",
    "\n",
    "# 3. IDs présents dans meta mais pas dans clicks\n",
    "missing_in_clicks = meta_ids - click_ids\n",
    "print(f\"IDs en meta mais pas en clicks : {len(missing_in_clicks)}\")\n",
    "print(\"Quelques exemples :\", list(missing_in_clicks)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7513d92-fba0-416e-827c-3db057054c37",
   "metadata": {},
   "source": [
    "Which implies that users have read the same articles multiples times, and that some articles have never been read\n",
    "\n",
    "Sounds strange and inaccurate\n",
    "\n",
    "Retrain now with full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55abdb5d-f60a-4756-bdec-449454eecde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 3.2 Agréger en comptant les clics par (user, article)\\nratings = (\\n    clicks_full\\n    .groupby([\"user_id\",\"click_article_id\"])\\n    .size()\\n    .reset_index(name=\"rating\")\\n)\\n\\nprint(ratings.shape)\\ndisplay(ratings.head())\\nprint(ratings[\"rating\"].describe())'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 3.2 Agréger en comptant les clics par (user, article)\n",
    "ratings = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "\n",
    "print(ratings.shape)\n",
    "display(ratings.head())\n",
    "print(ratings[\"rating\"].describe())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e37d544f-1e61-4257-979c-07856feda446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ratings[\"rating\"].unique()'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ratings[\"rating\"].unique()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77c1b65f-4311-44e2-8aa4-ffad6c0554a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#4(Optionnel) Calculer un dwell_time pour un rating pondéré\\nclicks_full = clicks_full.sort_values(\\n    [\"user_id\",\"session_id\",\"click_timestamp\"]\\n)\\nclicks_full[\"next_ts\"] = (\\n    clicks_full\\n    .groupby([\"user_id\",\"session_id\"])[\"click_timestamp\"]\\n    .shift(-1)\\n)\\nclicks_full[\"dwell_time\"] = (\\n    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\\n).fillna(0)\\n\\n# 5. Construire le DataFrame de ratings sur counts\\nratings_count = (\\n    clicks_full\\n    .groupby([\"user_id\",\"click_article_id\"])\\n    .size()\\n    .reset_index(name=\"rating\")\\n)\\nprint(ratings_count[\"rating\"].describe())\\n\\n# 6. Ou bien sur dwell_time\\nratings_time = (\\n    clicks_full\\n    .groupby([\"user_id\",\"click_article_id\"])[\"dwell_time\"]\\n    .sum()\\n    .reset_index(name=\"rating\")\\n)\\nprint(ratings_time[\"rating\"].describe())'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#4(Optionnel) Calculer un dwell_time pour un rating pondéré\n",
    "clicks_full = clicks_full.sort_values(\n",
    "    [\"user_id\",\"session_id\",\"click_timestamp\"]\n",
    ")\n",
    "clicks_full[\"next_ts\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"session_id\"])[\"click_timestamp\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "clicks_full[\"dwell_time\"] = (\n",
    "    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\n",
    ").fillna(0)\n",
    "\n",
    "# 5. Construire le DataFrame de ratings sur counts\n",
    "ratings_count = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "print(ratings_count[\"rating\"].describe())\n",
    "\n",
    "# 6. Ou bien sur dwell_time\n",
    "ratings_time = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"click_article_id\"])[\"dwell_time\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "print(ratings_time[\"rating\"].describe())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "520f10ab-c376-48ac-8869-68bb8017f559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from surprise import Dataset, Reader, SVD\\nfrom surprise.model_selection import train_test_split\\nfrom surprise import accuracy\\n\\n# Choix du rating\\nratings = ratings_count  # ou ratings_time\\n\\nreader = Reader(rating_scale=(ratings.rating.min(), ratings.rating.max()))\\ndata   = Dataset.load_from_df(\\n    ratings[[\"user_id\",\"click_article_id\",\"rating\"]],\\n    reader\\n)\\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\\n\\nalgo = SVD(n_factors=50, random_state=42)\\nalgo.fit(trainset)\\n\\npreds = algo.test(testset)\\nprint(\"RMSE:\", accuracy.rmse(preds))\\nprint(\"MAE: \", accuracy.mae(preds))\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Choix du rating\n",
    "ratings = ratings_count  # ou ratings_time\n",
    "\n",
    "reader = Reader(rating_scale=(ratings.rating.min(), ratings.rating.max()))\n",
    "data   = Dataset.load_from_df(\n",
    "    ratings[[\"user_id\",\"click_article_id\",\"rating\"]],\n",
    "    reader\n",
    ")\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=42)\n",
    "algo.fit(trainset)\n",
    "\n",
    "preds = algo.test(testset)\n",
    "print(\"RMSE:\", accuracy.rmse(preds))\n",
    "print(\"MAE: \", accuracy.mae(preds))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb224381-eb47-4350-9df7-2588c7a940b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#dwell time\\n\\n# 2. Calculer le dwell_time (temps passé sur chaque article au sein de chaque session)\\nclicks_full = clicks_full.sort_values(\\n    [\"user_id\", \"session_id\", \"click_timestamp\"]\\n)\\n\\n# Pour chaque clic, on prend le timestamp du clic suivant dans la même session\\nclicks_full[\"next_ts\"] = (\\n    clicks_full\\n    .groupby([\"user_id\", \"session_id\"])[\"click_timestamp\"]\\n    .shift(-1)\\n)\\n\\n# dwell_time = différence au clic suivant, ou 0 si c\\'est le dernier clic de la session\\nclicks_full[\"dwell_time\"] = (\\n    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\\n).fillna(0)\\n\\n# 3. Construire le DataFrame de ratings sur la somme des dwell_time par (user, article)\\nratings_time = (\\n    clicks_full\\n    .groupby([\"user_id\", \"click_article_id\"])[\"dwell_time\"]\\n    .sum()\\n    .reset_index(name=\"rating\")\\n)\\n\\n# (Optionnel) Appliquer une transformation log+1 pour atténuer les valeurs extrêmes\\nratings_time[\"rating\"] = np.log1p(ratings_time[\"rating\"])\\n\\n# 4. Charger ces ratings dans Surprise et entraîner un modèle SVD\\nreader = Reader(rating_scale=(ratings_time[\"rating\"].min(), ratings_time[\"rating\"].max()))\\ndata   = Dataset.load_from_df(\\n    ratings_time[[\"user_id\", \"click_article_id\", \"rating\"]],\\n    reader\\n)\\n\\ntrainset, testset = train_test_split(data, test_size=0.2, random_state=42)\\n\\nalgo = SVD(n_factors=50, random_state=42)\\nalgo.fit(trainset)\\n\\n# 5. Évaluer sur le testset (RMSE / MAE)\\npreds = algo.test(testset)\\nprint(\"RMSE:\", accuracy.rmse(preds))\\nprint(\"MAE: \", accuracy.mae(preds))\\n\\n# 6. Exemple de prédiction pour un utilisateur & un article donné\\n#    Format : algo.predict(uid, iid, r_ui=None, verbose=True)\\n#    - uid = ID utilisateur (doit exister dans trainset ou non ; Surprise peut faire du cold-start)\\n#    - iid = ID article (doit exister dans trainset ou non)\\n#    - r_ui = rating réel si connu, sinon None\\n#    - verbose = True pour afficher la prédiction détaillée\\n\\nuser_id    = 1234    # remplacer par un user_id de ton choix\\narticle_id = 157541  # remplacer par un click_article_id de ton choix\\n\\nprediction = algo.predict(uid=user_id, iid=article_id, r_ui=None, verbose=True)\\n# prediction.est est la valeur prédite (log(dwell_time+1)) pour ce couple (user_id, article_id)\\n\\n# Si tu veux récupérer la valeur sous forme de dwell_time estimé, fais :\\nlog_est = prediction.est\\ndwell_time_est = np.expm1(log_est)  # inverse de np.log1p\\nprint(f\"Estimation de dwell_time pour user {user_id}, article {article_id}: {dwell_time_est:.2f} ms\")'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#dwell time\n",
    "\n",
    "# 2. Calculer le dwell_time (temps passé sur chaque article au sein de chaque session)\n",
    "clicks_full = clicks_full.sort_values(\n",
    "    [\"user_id\", \"session_id\", \"click_timestamp\"]\n",
    ")\n",
    "\n",
    "# Pour chaque clic, on prend le timestamp du clic suivant dans la même session\n",
    "clicks_full[\"next_ts\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\", \"session_id\"])[\"click_timestamp\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "\n",
    "# dwell_time = différence au clic suivant, ou 0 si c'est le dernier clic de la session\n",
    "clicks_full[\"dwell_time\"] = (\n",
    "    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\n",
    ").fillna(0)\n",
    "\n",
    "# 3. Construire le DataFrame de ratings sur la somme des dwell_time par (user, article)\n",
    "ratings_time = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\", \"click_article_id\"])[\"dwell_time\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"rating\")\n",
    ")\n",
    "\n",
    "# (Optionnel) Appliquer une transformation log+1 pour atténuer les valeurs extrêmes\n",
    "ratings_time[\"rating\"] = np.log1p(ratings_time[\"rating\"])\n",
    "\n",
    "# 4. Charger ces ratings dans Surprise et entraîner un modèle SVD\n",
    "reader = Reader(rating_scale=(ratings_time[\"rating\"].min(), ratings_time[\"rating\"].max()))\n",
    "data   = Dataset.load_from_df(\n",
    "    ratings_time[[\"user_id\", \"click_article_id\", \"rating\"]],\n",
    "    reader\n",
    ")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=42)\n",
    "algo.fit(trainset)\n",
    "\n",
    "# 5. Évaluer sur le testset (RMSE / MAE)\n",
    "preds = algo.test(testset)\n",
    "print(\"RMSE:\", accuracy.rmse(preds))\n",
    "print(\"MAE: \", accuracy.mae(preds))\n",
    "\n",
    "# 6. Exemple de prédiction pour un utilisateur & un article donné\n",
    "#    Format : algo.predict(uid, iid, r_ui=None, verbose=True)\n",
    "#    - uid = ID utilisateur (doit exister dans trainset ou non ; Surprise peut faire du cold-start)\n",
    "#    - iid = ID article (doit exister dans trainset ou non)\n",
    "#    - r_ui = rating réel si connu, sinon None\n",
    "#    - verbose = True pour afficher la prédiction détaillée\n",
    "\n",
    "user_id    = 1234    # remplacer par un user_id de ton choix\n",
    "article_id = 157541  # remplacer par un click_article_id de ton choix\n",
    "\n",
    "prediction = algo.predict(uid=user_id, iid=article_id, r_ui=None, verbose=True)\n",
    "# prediction.est est la valeur prédite (log(dwell_time+1)) pour ce couple (user_id, article_id)\n",
    "\n",
    "# Si tu veux récupérer la valeur sous forme de dwell_time estimé, fais :\n",
    "log_est = prediction.est\n",
    "dwell_time_est = np.expm1(log_est)  # inverse de np.log1p\n",
    "print(f\"Estimation de dwell_time pour user {user_id}, article {article_id}: {dwell_time_est:.2f} ms\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04868424-5eae-4964-b28c-80956936a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import pickle\\n\\n# Define save path\\nsave_path = os.path.join(\"models_in_progress\", \"cf_model.pkl\")\\n\\n# Serialize\\nwith open(save_path, \"wb\") as f_out:\\n    pickle.dump(algo, f_out)\\n\\nprint(os.listdir(\"models_in_progress\"))\\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import pickle\n",
    "\n",
    "# Define save path\n",
    "save_path = os.path.join(\"models_in_progress\", \"cf_model.pkl\")\n",
    "\n",
    "# Serialize\n",
    "with open(save_path, \"wb\") as f_out:\n",
    "    pickle.dump(algo, f_out)\n",
    "\n",
    "print(os.listdir(\"models_in_progress\"))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc212419-35b2-48cb-ae52-4e8128eada5c",
   "metadata": {},
   "source": [
    "nb de click par user sur un article / pondère par activité user lors de sa session (nb total de click par session)\n",
    "\n",
    "par user's session  : \\\n",
    "nb total de click \\\n",
    "nb de click par article\n",
    "\n",
    "temps passé sur chaque article \\\n",
    "nb de click sur un même lien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6f1840-42be-4db1-a671-121e49988580",
   "metadata": {},
   "source": [
    "## second CB, more implicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "774c060a-3089-4e4f-895e-54729bcad03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanam\\AppData\\Local\\Temp\\ipykernel_21556\\3556110278.py:10: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# 1) On calcule, pour chaque clic, le timestamp du clic suivant DANS LA MÊME SESSION\n",
    "clicks_full[\"next_ts\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\", \"session_id\"])[\"click_timestamp\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "# 2) On calcule le dwell_time : temps écoulé entre clic courant et clic suivant\n",
    "clicks_full[\"dwell_time\"] = (\n",
    "    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\n",
    ").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd0949e9-dc9f-48d7-9bf9-f4ba56dd9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) On agrège le dwell_time par couple (user_id, click_article_id)\n",
    "dwell_per_pair = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\", \"click_article_id\"])[\"dwell_time\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_dwell_time\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "59a6129b-e78c-43fa-80f0-9668ac490056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clicks_full = clicks_full.sort_values(\\n    [\"user_id\", \"session_id\", \"click_timestamp\"]\\n)\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clicks_full = clicks_full.sort_values(\n",
    "    [\"user_id\", \"session_id\", \"click_timestamp\"]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f34762af-d09f-4bf8-a693-ad571939f8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwell_per_pair[\"dwell_score\"] = np.log1p(dwell_per_pair[\"total_dwell_time\"])\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dwell_per_pair[\"dwell_score\"] = np.log1p(dwell_per_pair[\"total_dwell_time\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f0069a91-9f57-4923-93e8-9ff79be8bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# session_size est déjà donnée dans le dataset (nombre de clics dans la session)\n",
    "# Si ce n’était pas le cas, on ferait :\n",
    "# session_counts = (\n",
    "#   clicks_full.groupby([\"user_id\",\"session_id\"])\n",
    "#   .size().reset_index(name=\"session_size\")\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec4beb35-b586-4d58-811f-b6ec1757521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) On calcule, pour chaque ligne, la proportion de clics sur le même article DANS LA SESSION\n",
    "clicks_full[\"clicks_same_session\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"session_id\",\"click_article_id\"])\n",
    "    [\"click_article_id\"]\n",
    "    .transform(\"count\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9efd649b-02b9-4fa4-b02f-087c1c371929",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clicks_full[\"session_weight\"] = (\n",
    "    clicks_full[\"clicks_same_session\"] / clicks_full[\"session_size\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "82564701-556b-44d6-a4bf-5d5487b88b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) On agrège ce poids RELATIF par couple (user, article)\n",
    "session_weight_per_pair = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\", \"click_article_id\"])[\"session_weight\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_session_weight\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31655da5-6fbe-4944-9d8f-140de456d27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) On compte dans combien de SESSIONS distinctes l'utilisateur a cliqué sur l'article\n",
    "sessions_per_pair = (\n",
    "    clicks_full\n",
    "    .drop_duplicates(subset=[\"user_id\", \"session_id\", \"click_article_id\"])\n",
    "    .groupby([\"user_id\", \"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_sessions_clicked\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5c69605e-6c2d-4c24-a4fd-ceae04fadecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "0    0.5\n",
      "1    0.5\n",
      "2    0.5\n",
      "3    0.5\n",
      "4    0.5\n",
      "Name: total_session_weight, dtype: object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(type(session_weight_per_pair[\"total_session_weight\"]))            # doit être <class 'pandas.core.series.Series'>\n",
    "print(session_weight_per_pair[\"total_session_weight\"].head())          # un aperçu des 5 premières valeurs\n",
    "print(session_weight_per_pair[\"total_session_weight\"].dtype)           # dtype, ex. float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "41eb785e-7b91-46e4-8f2c-56c817fd5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) (Optionnel) On transforme en log pour atténuer l'effet des grosses valeurs\n",
    "vals = session_weight_per_pair[\"total_session_weight\"].to_numpy(dtype=float)\n",
    "session_weight_per_pair[\"sw_score\"] = np.log1p(vals)\n",
    "\n",
    "dwell_per_pair[\"dwell_score\"] = np.log1p(dwell_per_pair[\"total_dwell_time\"])\n",
    "#session_weight_per_pair[\"sw_score\"] = np.log1p(session_weight_per_pair[\"total_session_weight\"])\n",
    "sessions_per_pair[\"sc_score\"] = np.log1p(sessions_per_pair[\"n_sessions_clicked\"])\n",
    "\n",
    "#sessions_per_pair[\"session_count_score\"] = np.log1p(sessions_per_pair[\"n_sessions_clicked\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a6a3e4c-13fc-47c4-88f3-1e8f34fc86b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 4.1. rename des colonnes pour homogénéité\\ndwell_per_pair = dwell_per_pair.rename(\\n    columns={\"click_article_id\": \"article_id\"}\\n)\\n\\nsession_weight_per_pair = session_weight_per_pair.rename(\\n    columns={\"click_article_id\": \"article_id\", \"total_session_weight\": \"sw_score\"}\\n)\\n\\nsessions_per_pair = sessions_per_pair.rename(\\n    columns={\"click_article_id\": \"article_id\", \"n_sessions_clicked\": \"n_sess\", \"session_count_score\": \"sc_score\"}\\n)\\n\\n# 4.2. Merge successifs\\nratings_imp = dwell_per_pair.merge(\\n    session_weight_per_pair,\\n    on=[\"user_id\",\"article_id\"],\\n    how=\"outer\"\\n).merge(\\n    sessions_per_pair,\\n    on=[\"user_id\",\"article_id\"],\\n    how=\"outer\"\\n)\\n\\n# 4.3. Remplir les NaN (si un utilisateur n’avait jamais de dwell_time ou n’apparaît que dans l’une des deux tables)\\nratings_imp = ratings_imp.fillna(0)'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# 4.1. rename des colonnes pour homogénéité\n",
    "dwell_per_pair = dwell_per_pair.rename(\n",
    "    columns={\"click_article_id\": \"article_id\"}\n",
    ")\n",
    "\n",
    "session_weight_per_pair = session_weight_per_pair.rename(\n",
    "    columns={\"click_article_id\": \"article_id\", \"total_session_weight\": \"sw_score\"}\n",
    ")\n",
    "\n",
    "sessions_per_pair = sessions_per_pair.rename(\n",
    "    columns={\"click_article_id\": \"article_id\", \"n_sessions_clicked\": \"n_sess\", \"session_count_score\": \"sc_score\"}\n",
    ")\n",
    "\n",
    "# 4.2. Merge successifs\n",
    "ratings_imp = dwell_per_pair.merge(\n",
    "    session_weight_per_pair,\n",
    "    on=[\"user_id\",\"article_id\"],\n",
    "    how=\"outer\"\n",
    ").merge(\n",
    "    sessions_per_pair,\n",
    "    on=[\"user_id\",\"article_id\"],\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "# 4.3. Remplir les NaN (si un utilisateur n’avait jamais de dwell_time ou n’apparaît que dans l’une des deux tables)\n",
    "ratings_imp = ratings_imp.fillna(0)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42d8fbe6-3747-4a55-94a7-752249f9bc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanam\\AppData\\Local\\Temp\\ipykernel_21556\\16259381.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n"
     ]
    }
   ],
   "source": [
    "# 8) On fusionne ces trois DataFrames sur (user_id, article_id)\n",
    "from functools import reduce\n",
    "\n",
    "dfs = [\n",
    "    dwell_per_pair.rename(columns={\"click_article_id\":\"article_id\"}),\n",
    "    session_weight_per_pair.rename(columns={\"click_article_id\":\"article_id\"}),\n",
    "    sessions_per_pair.rename(columns={\"click_article_id\":\"article_id\"})\n",
    "]\n",
    "ratings_imp = reduce(\n",
    "    lambda left, right: left.merge(right, on=[\"user_id\",\"article_id\"], how=\"left\"),\n",
    "    dfs\n",
    ").fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c3a59fc-97b7-4e16-b1be-7c260b9bcaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>dwell_score</th>\n",
       "      <th>total_session_weight</th>\n",
       "      <th>sw_score</th>\n",
       "      <th>n_sessions_clicked</th>\n",
       "      <th>sc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>87205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>87224</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>96755</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157541</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950705</th>\n",
       "      <td>322894</td>\n",
       "      <td>168401</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950706</th>\n",
       "      <td>322895</td>\n",
       "      <td>63746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950707</th>\n",
       "      <td>322895</td>\n",
       "      <td>289197</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950708</th>\n",
       "      <td>322896</td>\n",
       "      <td>30760</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950709</th>\n",
       "      <td>322896</td>\n",
       "      <td>157507</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.405465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950710 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  article_id  total_dwell_time  dwell_score  \\\n",
       "0              0       68866                 0     0.000000   \n",
       "1              0       87205                 0     0.000000   \n",
       "2              0       87224             30000    10.308986   \n",
       "3              0       96755             30000    10.308986   \n",
       "4              0      157541             30000    10.308986   \n",
       "...          ...         ...               ...          ...   \n",
       "2950705   322894      168401                 0     0.000000   \n",
       "2950706   322895       63746                 0     0.000000   \n",
       "2950707   322895      289197             30000    10.308986   \n",
       "2950708   322896       30760             30000    10.308986   \n",
       "2950709   322896      157507                 0     0.000000   \n",
       "\n",
       "         total_session_weight  sw_score  n_sessions_clicked  sc_score  \n",
       "0                         0.5  0.405465                   1  0.693147  \n",
       "1                         0.5  0.405465                   1  0.693147  \n",
       "2                         0.5  0.405465                   1  0.693147  \n",
       "3                         0.5  0.405465                   1  0.693147  \n",
       "4                         0.5  0.405465                   1  0.693147  \n",
       "...                       ...       ...                 ...       ...  \n",
       "2950705                   0.5  0.405465                   1  0.693147  \n",
       "2950706                   0.5  0.405465                   1  0.693147  \n",
       "2950707                   0.5  0.405465                   1  0.693147  \n",
       "2950708                   0.5  0.405465                   1  0.693147  \n",
       "2950709                   0.5  0.405465                   1  0.693147  \n",
       "\n",
       "[2950710 rows x 8 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c052b074-cb34-4d88-9ed2-d68d07010f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user_id', 'article_id', 'total_dwell_time', 'dwell_score', 'total_session_weight', 'sw_score', 'n_sessions_clicked', 'sc_score']\n"
     ]
    }
   ],
   "source": [
    "print(ratings_imp.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cc8af446-556e-46e2-a47a-b282b3f6057a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Normalisation Min-Max de chacune de ces trois composantes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ratings_imp[\"dwell_norm\"] = scaler.fit_transform(ratings_imp[[\"dwell_score\"]])\n",
    "ratings_imp[\"sw_norm\"]    = scaler.fit_transform(ratings_imp[[\"sw_score\"]])\n",
    "ratings_imp[\"sc_norm\"]    = scaler.fit_transform(ratings_imp[[\"sc_score\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e148b4db-27ed-4d41-8a5c-0e85fb39412e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.preprocessing import MinMaxScaler\\n\\nscaler = MinMaxScaler()\\n\\n# On normalise dwell_score (qui est déjà log+1)\\nratings_imp[\"dwell_norm\"] = scaler.fit_transform(\\n    ratings_imp[[\"dwell_score\"]]\\n)\\n\\n# On normalise sw_score\\nratings_imp[\"sw_norm\"] = scaler.fit_transform(\\n    ratings_imp[[\"sw_score\"]]\\n)\\n\\n# On normalise sc_score\\nratings_imp[\"sc_norm\"] = scaler.fit_transform(\\n    ratings_imp[[\"sc_score\"]]\\n)\\n\\n# Puis on combine\\nw1, w2, w3 = 0.5, 0.3, 0.2\\nratings_imp[\"rating_imp\"] = (\\n    w1 * ratings_imp[\"dwell_norm\"]\\n  + w2 * ratings_imp[\"sw_norm\"]\\n  + w3 * ratings_imp[\"sc_norm\"]\\n)\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# On normalise dwell_score (qui est déjà log+1)\n",
    "ratings_imp[\"dwell_norm\"] = scaler.fit_transform(\n",
    "    ratings_imp[[\"dwell_score\"]]\n",
    ")\n",
    "\n",
    "# On normalise sw_score\n",
    "ratings_imp[\"sw_norm\"] = scaler.fit_transform(\n",
    "    ratings_imp[[\"sw_score\"]]\n",
    ")\n",
    "\n",
    "# On normalise sc_score\n",
    "ratings_imp[\"sc_norm\"] = scaler.fit_transform(\n",
    "    ratings_imp[[\"sc_score\"]]\n",
    ")\n",
    "\n",
    "# Puis on combine\n",
    "w1, w2, w3 = 0.5, 0.3, 0.2\n",
    "ratings_imp[\"rating_imp\"] = (\n",
    "    w1 * ratings_imp[\"dwell_norm\"]\n",
    "  + w2 * ratings_imp[\"sw_norm\"]\n",
    "  + w3 * ratings_imp[\"sc_norm\"]\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65d02370-ff97-43c9-9c31-e66de8973d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Combinaison pondérée en un seul rating implicite\n",
    "w1, w2, w3 = 0.5, 0.3, 0.2\n",
    "ratings_imp[\"rating_imp\"] = (\n",
    "    w1 * ratings_imp[\"dwell_norm\"]\n",
    "  + w2 * ratings_imp[\"sw_norm\"]\n",
    "  + w3 * ratings_imp[\"sc_norm\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b05e7ae7-9b97-4f17-974b-84596252ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) (Optionnel) Mise à l’échelle pour Surprise, p.ex. dans [1,5]\n",
    "ratings_imp[\"rating_final\"] = 1 + 4 * ratings_imp[\"rating_imp\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c40976cb-8fc5-4f41-843a-9326f07345a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(\n",
    "    ratings_imp[[\"user_id\",\"article_id\",\"rating_final\"]],\n",
    "    reader\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53656071-f91c-4a85-85dd-337a4f2c43c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Charger le dataset complet de clics\n",
    "clicks_dir = \"data/archive/clicks/clicks\"\n",
    "files = [f for f in os.listdir(clicks_dir) if f.endswith(\".csv\")]\n",
    "dfs = [pd.read_csv(os.path.join(clicks_dir, f)) for f in files]\n",
    "clicks_full = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1983704-2561-4968-b0db-208f80a204da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kanam\\AppData\\Local\\Temp\\ipykernel_21556\\3181132234.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ).fillna(0)\n",
      "C:\\Users\\kanam\\AppData\\Local\\Temp\\ipykernel_21556\\3181132234.py:60: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  ratings_imp = ratings_imp.fillna(0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "      <th>total_dwell_time</th>\n",
       "      <th>dwell_score</th>\n",
       "      <th>sw_score</th>\n",
       "      <th>n_sess</th>\n",
       "      <th>sc_score</th>\n",
       "      <th>dwell_norm</th>\n",
       "      <th>sw_norm</th>\n",
       "      <th>sc_norm</th>\n",
       "      <th>rating_imp</th>\n",
       "      <th>rating_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>68866</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>1.107489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>87205</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026872</td>\n",
       "      <td>1.107489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>87224</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273314</td>\n",
       "      <td>2.093256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>96755</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273314</td>\n",
       "      <td>2.093256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>157541</td>\n",
       "      <td>30000</td>\n",
       "      <td>10.308986</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>0.492884</td>\n",
       "      <td>0.089574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273314</td>\n",
       "      <td>2.093256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id  total_dwell_time  dwell_score  sw_score  n_sess  \\\n",
       "0        0       68866                 0     0.000000       0.5       1   \n",
       "1        0       87205                 0     0.000000       0.5       1   \n",
       "2        0       87224             30000    10.308986       0.5       1   \n",
       "3        0       96755             30000    10.308986       0.5       1   \n",
       "4        0      157541             30000    10.308986       0.5       1   \n",
       "\n",
       "   sc_score  dwell_norm   sw_norm  sc_norm  rating_imp  rating_final  \n",
       "0  0.693147    0.000000  0.089574      0.0    0.026872      1.107489  \n",
       "1  0.693147    0.000000  0.089574      0.0    0.026872      1.107489  \n",
       "2  0.693147    0.492884  0.089574      0.0    0.273314      2.093256  \n",
       "3  0.693147    0.492884  0.089574      0.0    0.273314      2.093256  \n",
       "4  0.693147    0.492884  0.089574      0.0    0.273314      2.093256  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Calcul du dwell_time\n",
    "clicks_full = clicks_full.sort_values(\n",
    "    [\"user_id\",\"session_id\",\"click_timestamp\"]\n",
    ")\n",
    "clicks_full[\"next_ts\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"session_id\"])[\"click_timestamp\"]\n",
    "    .shift(-1)\n",
    ")\n",
    "clicks_full[\"dwell_time\"] = (\n",
    "    clicks_full[\"next_ts\"] - clicks_full[\"click_timestamp\"]\n",
    ").fillna(0)\n",
    "\n",
    "# 3. Calcul du dwell_score = log1p(total_dwell_time)\n",
    "dwell_per_pair = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"click_article_id\"])[\"dwell_time\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"total_dwell_time\")\n",
    ")\n",
    "dwell_per_pair[\"dwell_score\"] = np.log1p(dwell_per_pair[\"total_dwell_time\"])\n",
    "\n",
    "# 4. Calcul du poids par session (session_weight)\n",
    "clicks_full[\"clicks_same_session\"] = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"session_id\",\"click_article_id\"])\n",
    "    [\"click_article_id\"]\n",
    "    .transform(\"count\")\n",
    ")\n",
    "clicks_full[\"session_weight\"] = (\n",
    "    clicks_full[\"clicks_same_session\"] / clicks_full[\"session_size\"]\n",
    ")\n",
    "\n",
    "session_weight_per_pair = (\n",
    "    clicks_full\n",
    "    .groupby([\"user_id\",\"click_article_id\"])[\"session_weight\"]\n",
    "    .sum()\n",
    "    .reset_index(name=\"sw_score\")\n",
    ")\n",
    "\n",
    "# 5. Calcul de la fréquence multi-session (sc_score)\n",
    "sessions_per_pair = (\n",
    "    clicks_full.drop_duplicates(\n",
    "        subset=[\"user_id\",\"session_id\",\"click_article_id\"]\n",
    "    )\n",
    "    .groupby([\"user_id\",\"click_article_id\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"n_sessions_clicked\")\n",
    ")\n",
    "sessions_per_pair[\"sc_score\"] = np.log1p(sessions_per_pair[\"n_sessions_clicked\"])\n",
    "\n",
    "# 6. Fusion des métriques\n",
    "dwell2 = dwell_per_pair.rename(columns={\"click_article_id\":\"article_id\"})\n",
    "sw2    = session_weight_per_pair.rename(columns={\"click_article_id\":\"article_id\"})\n",
    "sc2    = sessions_per_pair.rename(columns={\"click_article_id\":\"article_id\", \"n_sessions_clicked\":\"n_sess\"})\n",
    "\n",
    "ratings_imp = dwell2.merge(sw2, on=[\"user_id\",\"article_id\"], how=\"outer\") \\\n",
    "                    .merge(sc2, on=[\"user_id\",\"article_id\"], how=\"outer\")\n",
    "\n",
    "ratings_imp = ratings_imp.fillna(0)\n",
    "\n",
    "# 7. Normalisation Min-Max de chaque score\n",
    "scaler = MinMaxScaler()\n",
    "ratings_imp[\"dwell_norm\"] = scaler.fit_transform(\n",
    "    ratings_imp[[\"dwell_score\"]]\n",
    ")\n",
    "ratings_imp[\"sw_norm\"]    = scaler.fit_transform(\n",
    "    ratings_imp[[\"sw_score\"]]\n",
    ")\n",
    "ratings_imp[\"sc_norm\"]    = scaler.fit_transform(\n",
    "    ratings_imp[[\"sc_score\"]]\n",
    ")\n",
    "\n",
    "# 8. Combinaison pondérée\n",
    "w1, w2, w3 = 0.5, 0.3, 0.2\n",
    "ratings_imp[\"rating_imp\"] = (\n",
    "    w1 * ratings_imp[\"dwell_norm\"]\n",
    "  + w2 * ratings_imp[\"sw_norm\"]\n",
    "  + w3 * ratings_imp[\"sc_norm\"]\n",
    ")\n",
    "\n",
    "# 9. Mise à l’échelle finale (1 à 5) pour Surprise\n",
    "ratings_imp[\"rating_final\"] = 1 + 4 * ratings_imp[\"rating_imp\"]\n",
    "\n",
    "ratings_imp.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "180058ad-54e5-4981-9626-2ecad1e7faeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.5164\n",
      "RMSE: 0.5163591623626093\n",
      "MAE:  0.4752\n",
      "MAE:  0.4751698691392017\n"
     ]
    }
   ],
   "source": [
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "data = Dataset.load_from_df(\n",
    "    ratings_imp[[\"user_id\",\"article_id\",\"rating_final\"]],\n",
    "    reader\n",
    ")\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "algo_cf = SVD(n_factors=50, random_state=42)\n",
    "algo_cf.fit(trainset)\n",
    "\n",
    "preds = algo_cf.test(testset)\n",
    "print(\"RMSE:\", accuracy.rmse(preds))\n",
    "print(\"MAE: \", accuracy.mae(preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c7e9207-a85d-4a36-a938-c6358a2ae1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple d'utilisateur : 0\n",
      "Exemple d'utilisateur : 68866\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(uid=0, iid=68866, r_ui=None, est=1.5178435034919495, details={'was_impossible': False})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_user = ratings_imp[\"user_id\"].iloc[0]\n",
    "print(f\"Exemple d'utilisateur : {demo_user}\")\n",
    "demo_article = ratings_imp[\"article_id\"].iloc[0]\n",
    "print(f\"Exemple d'article : {demo_article}\")\n",
    "\n",
    "algo_cf.predict(demo_user, demo_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "88b36a75-bb94-4dc3-a5f1-9b882200064c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['article_id', 'category_id', 'created_at_ts', 'publisher_id',\n",
       "       'words_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_meta.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce607067-a1f4-460f-9049-a413245a99c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisateur de démonstration : 0\n",
      "Articles déjà cliqués (8): [68866, 157541, 87205, 313996, 96755]…\n",
      "Nombre de candidats CF possibles : 364039\n",
      "Top 5 recommandations CF pures :\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>score_cf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>257732</td>\n",
       "      <td>391</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>1507648925000</td>\n",
       "      <td>2.063084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194199</td>\n",
       "      <td>317</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>1507975860000</td>\n",
       "      <td>2.056109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>227849</td>\n",
       "      <td>374</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>1507500412000</td>\n",
       "      <td>2.022434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>314286</td>\n",
       "      <td>431</td>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>1507466177000</td>\n",
       "      <td>2.006254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>136553</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>1507625576000</td>\n",
       "      <td>1.989056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id  publisher_id  words_count  created_at_ts  score_cf\n",
       "0      257732          391             0          127  1507648925000  2.063084\n",
       "1      194199          317             0          185  1507975860000  2.056109\n",
       "2      227849          374             0          166  1507500412000  2.022434\n",
       "3      314286          431             0          161  1507466177000  2.006254\n",
       "4      136553          255             0          113  1507625576000  1.989056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Choix du user_id pour la démo (par exemple, le premier de ratings_imp)\n",
    "demo_user = ratings_imp[\"user_id\"].iloc[0]\n",
    "print(f\"Utilisateur de démonstration : {demo_user}\")\n",
    "\n",
    "# 2. Historique CF : lister les articles déjà vus par ce user\n",
    "user_seen = set(ratings_imp.loc[\n",
    "    ratings_imp[\"user_id\"] == demo_user, \"article_id\"\n",
    "].tolist())\n",
    "print(f\"Articles déjà cliqués ({len(user_seen)}): {list(user_seen)[:5]}…\")\n",
    "\n",
    "# 3. Préparer le pool de candidats CF : tous les article_id de data_meta non vus\n",
    "all_articles = set(data_meta[\"article_id\"].tolist())\n",
    "candidates = list(all_articles - user_seen)\n",
    "print(f\"Nombre de candidats CF possibles : {len(candidates)}\")\n",
    "\n",
    "# 4. Prédire un score CF pour chaque candidat\n",
    "cf_algo = algo_cf\n",
    "\n",
    "cf_preds = []\n",
    "for iid in candidates:\n",
    "    pred = cf_algo.predict(uid=demo_user, iid=iid, r_ui=None, verbose=False)\n",
    "    cf_preds.append((iid, pred.est))\n",
    "\n",
    "# 5. Trier par score décroissant et prendre le top-k\n",
    "k = 5\n",
    "topk_cf = sorted(cf_preds, key=lambda x: x[1], reverse=True)[:k]\n",
    "topk_ids = [iid for iid, _ in topk_cf]\n",
    "topk_scores = [score for _, score in topk_cf]\n",
    "\n",
    "# 6. Construire un DataFrame résultat et joindre les métadonnées\n",
    "df_cf = pd.DataFrame({\n",
    "    \"article_id\": topk_ids,\n",
    "    \"score_cf\":   topk_scores\n",
    "})\n",
    "df_cf = df_cf.merge(\n",
    "    data_meta,\n",
    "    on=\"article_id\",\n",
    "    how=\"left\"\n",
    ")[[\n",
    "    \"article_id\",\"category_id\",\"publisher_id\",\"words_count\",\"created_at_ts\",\"score_cf\"\n",
    "]]\n",
    "\n",
    "# 7. Afficher les recommandations CF pures\n",
    "print(\"Top 5 recommandations CF pures :\")\n",
    "display(df_cf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccba89bc-71dd-40b6-a6cb-b1f7407acd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cf_model.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Define save path\n",
    "save_path = os.path.join(\"models_in_progress\", \"cf_model.pkl\")\n",
    "\n",
    "# Serialize\n",
    "with open(save_path, \"wb\") as f_out:\n",
    "    pickle.dump(cf_algo, f_out)\n",
    "\n",
    "print(os.listdir(\"models_in_progress\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f0447053-3f19-4c18-b645-73038d5b8ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 1) Création et fit sur training set\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaler.fit(ratings_imp[[\"rating_final\"]])\n",
    "\n",
    "# Define save path\n",
    "save_path = os.path.join(\"models_in_progress\", \"cf_scaler.pkl\")\n",
    "\n",
    "# 2) Sauvegarde\n",
    "with open(save_path, \"wb\") as f:\n",
    "    pickle.dump(scaler, f)\"\"\"\n",
    "#this is stupid because data € [1,5] so scaler can be retrained at every cold start without much resource consumption"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
