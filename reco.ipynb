{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e615e705-9b66-4ff9-855c-3f1d204afea5",
   "metadata": {},
   "source": [
    "# recommendation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e567a5b-2732-4892-a956-84e8d487f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from surprise import SVD, Reader, Dataset\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fefaa37d-db6e-47a3-a350-e165a65dc24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# 1. Chargement des embeddings et du modèle CF (SVD)\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# Ces variables globales seront initialisées lors du cold-start de la Function\n",
    "embeddings = None           # numpy.ndarray, shape=(n_articles, 250)\n",
    "meta = None                 # pandas.DataFrame avec colonnes [\"article_id\",\"category\",\"publisher\",\"words_count\",\"created_at\"]\n",
    "nn_index = None             # NearestNeighbors indexé sur embeddings\n",
    "cf_algo = None              # instance surprise.SVD entraînée\n",
    "CF_RADIUS = 500             # taille du pool CF/CB par défaut\n",
    "\n",
    "def load_embeddings_from_blob(blob_connection_string, container_name, blob_name, local_path):\n",
    "    \"\"\"\n",
    "    Télécharge le fichier pickle des embeddings depuis un Blob Azure,\n",
    "    puis charge le numpy.ndarray dans la variable globale `embeddings`.\n",
    "    \"\"\"\n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "    # 1) Télécharger le blob sur un disque local\n",
    "    blob_service = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "    container = blob_service.get_container_client(container_name)\n",
    "    blob_client = container.get_blob_client(blob_name)\n",
    "\n",
    "    with open(local_path, \"wb\") as f_out:\n",
    "        f_out.write(blob_client.download_blob().readall())\n",
    "\n",
    "    # 2) Charger le pickle\n",
    "    global embeddings\n",
    "    with open(local_path, \"rb\") as f_in:\n",
    "        embeddings = pickle.load(f_in)\n",
    "\n",
    "    # 3) Supprimer le fichier temporaire si nécessaire\n",
    "    # os.remove(local_path)\n",
    "\n",
    "\n",
    "def load_meta_from_blob(blob_connection_string, container_name, blob_name, local_path):\n",
    "    \"\"\"\n",
    "    Télécharge et charge le DataFrame meta (CSV).\n",
    "    \"\"\"\n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "    blob_service = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "    container = blob_service.get_container_client(container_name)\n",
    "    blob_client = container.get_blob_client(blob_name)\n",
    "\n",
    "    with open(local_path, \"wb\") as f_out:\n",
    "        f_out.write(blob_client.download_blob().readall())\n",
    "\n",
    "    global meta\n",
    "    meta = pd.read_csv(local_path)\n",
    "    # Si besoin, appliquer les mêmes transformations qu'en local\n",
    "    meta[\"created_at\"] = pd.to_datetime(\n",
    "        meta[\"created_at_ts\"], unit=\"s\", origin=\"unix\"\n",
    "    )\n",
    "    meta = meta.rename(columns={\n",
    "        \"category_id\": \"category\",\n",
    "        \"publisher_id\": \"publisher\"\n",
    "    })[\n",
    "        [\"article_id\",\"category\",\"publisher\",\"words_count\",\"created_at\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "def index_embeddings():\n",
    "    \"\"\"\n",
    "    Construit l'index NearestNeighbors sur `embeddings`.\n",
    "    \"\"\"\n",
    "    global nn_index\n",
    "    if embeddings is None:\n",
    "        raise RuntimeError(\"Embeddings non chargés\")\n",
    "    nn_index = NearestNeighbors(\n",
    "        n_neighbors=CF_RADIUS,\n",
    "        metric=\"cosine\",\n",
    "        algorithm=\"auto\"\n",
    "    )\n",
    "    nn_index.fit(embeddings)\n",
    "\n",
    "\n",
    "def load_cf_model_from_blob(blob_connection_string, container_name, blob_name, local_path):\n",
    "    \"\"\"\n",
    "    Télécharge un modèle Surprise (pickle) depuis Blob et le charge dans `cf_algo`.\n",
    "    \"\"\"\n",
    "    from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "    blob_service = BlobServiceClient.from_connection_string(blob_connection_string)\n",
    "    container = blob_service.get_container_client(container_name)\n",
    "    blob_client = container.get_blob_client(blob_name)\n",
    "\n",
    "    with open(local_path, \"wb\") as f_out:\n",
    "        f_out.write(blob_client.download_blob().readall())\n",
    "\n",
    "    global cf_algo\n",
    "    with open(local_path, \"rb\") as f_in:\n",
    "        cf_algo = pickle.load(f_in)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 2. Fonctions utilitaires CB et CF\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def build_user_profile(user_clicks):\n",
    "    \"\"\"\n",
    "    user_clicks : liste d'article_id que l'utilisateur a lus (ou cliqué).\n",
    "    Retourne la moyenne des embeddings correspondants (vecteur 250-d).\n",
    "    \"\"\"\n",
    "    if embeddings is None or meta is None:\n",
    "        raise RuntimeError(\"Embeddings ou meta manquants\")\n",
    "\n",
    "    # Récupérer les indices dans meta pour chaque article_id\n",
    "    idxs = meta.index[meta[\"article_id\"].isin(user_clicks)].tolist()\n",
    "    if len(idxs) == 0:\n",
    "        # Cold-start user : on renvoie un vecteur nul\n",
    "        return np.zeros(embeddings.shape[1])\n",
    "\n",
    "    user_embs = embeddings[idxs]\n",
    "    return np.mean(user_embs, axis=0)\n",
    "\n",
    "\n",
    "def score_cf_for_candidates(user_id, candidate_ids):\n",
    "    \"\"\"\n",
    "    Pour un user_id et une liste d'article_id candidates, \n",
    "    retourne les scores CF bruts (algo.predict().est).\n",
    "    \"\"\"\n",
    "    if cf_algo is None:\n",
    "        raise RuntimeError(\"CF model non chargé\")\n",
    "\n",
    "    scores = []\n",
    "    for iid in candidate_ids:\n",
    "        pred = cf_algo.predict(uid=user_id, iid=iid, r_ui=None, verbose=False)\n",
    "        scores.append(pred.est)\n",
    "    return np.array(scores)\n",
    "\n",
    "\n",
    "def normalize_minmax(array):\n",
    "    \"\"\"\n",
    "    Min-max scaling pour ramener 'array' dans [0,1].\n",
    "    Si min == max, on retourne un vecteur constant à 0.5.\n",
    "    \"\"\"\n",
    "    mn = array.min()\n",
    "    mx = array.max()\n",
    "    if mx > mn:\n",
    "        return (array - mn) / (mx - mn)\n",
    "    else:\n",
    "        return np.full_like(array, 0.5, dtype=float)\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 3. Fonction principale de recommandation hybride\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def recommend_hybrid(\n",
    "    user_id: int,\n",
    "    user_clicks: list,\n",
    "    k: int = 10,\n",
    "    alpha: float = 0.6,\n",
    "    total_candidates: int = CF_RADIUS\n",
    "):\n",
    "    \"\"\"\n",
    "    Renvoie un DataFrame pandas des k meilleurs articles pour user_id,\n",
    "    en mélangeant CB et CF.\n",
    "\n",
    "    - user_clicks : liste d'article_id (int) déjà cliqués par l'utilisateur\n",
    "    - k           : nombre final de recommandations\n",
    "    - alpha       : poids du CF (0-> uniquement CB, 1-> uniquement CF)\n",
    "    - total_candidates : taille du pool brut de candidats à scorer\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Construire le vecteur profil CB de l'utilisateur\n",
    "    user_vec = build_user_profile(user_clicks)  # vecteur 250-dim\n",
    "\n",
    "    # 2) Récupérer un pool de candidats CB via nearest neighbors\n",
    "    distances, indices = nn_index.kneighbors([user_vec], n_neighbors=total_candidates)\n",
    "    cand_idxs = indices[0]                # indices (rangées) dans meta\n",
    "    sims_cb = 1.0 - distances[0]          # sim = 1 - distance_cosinus\n",
    "\n",
    "    # 3) Construire le DataFrame de candidats\n",
    "    article_ids = meta.iloc[cand_idxs][\"article_id\"].values.tolist()\n",
    "    df_cand = pd.DataFrame({\n",
    "        \"article_id\": article_ids,\n",
    "        \"score_cb\": sims_cb\n",
    "    })\n",
    "\n",
    "    # 4) Calculer le score CF brut pour ces candidats\n",
    "    cf_raw = score_cf_for_candidates(user_id, article_ids)\n",
    "    df_cand[\"score_cf_raw\"] = cf_raw\n",
    "\n",
    "    # 5) Normaliser le score CF dans [0,1]\n",
    "    df_cand[\"score_cf\"] = normalize_minmax(df_cand[\"score_cf_raw\"].values)\n",
    "\n",
    "    # 6) Score hybride\n",
    "    df_cand[\"score_hybrid\"] = alpha * df_cand[\"score_cf\"] + (1 - alpha) * df_cand[\"score_cb\"]\n",
    "\n",
    "    # 7) Trier par score_hybrid et prendre les top-k\n",
    "    topk = (\n",
    "        df_cand\n",
    "        .sort_values(\"score_hybrid\", ascending=False)\n",
    "        .head(k)\n",
    "        .merge(\n",
    "            meta,\n",
    "            on=\"article_id\",\n",
    "            how=\"left\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # 8) Sélectionner/ordonner les colonnes à renvoyer\n",
    "    return topk[[\n",
    "        \"article_id\",\n",
    "        \"category\",\n",
    "        \"publisher\",\n",
    "        \"words_count\",\n",
    "        \"created_at\",\n",
    "        \"score_cb\",\n",
    "        \"score_cf\",\n",
    "        \"score_hybrid\"\n",
    "    ]].reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
